# =========================================================
# ğŸ”’ OpenFHE CKKSã‚’ä½¿ç”¨ã—ãŸã‚»ã‚­ãƒ¥ã‚¢é€£åˆå­¦ç¿’ã‚·ã‚¹ãƒ†ãƒ 
# =========================================================
#
# ã€ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®æ¦‚è¦ã€‘
# ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã¯ã€CIFAR-10ç”»åƒãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ä½¿ç”¨ã—ã¦ã€ä»¥ä¸‹2ã¤ã®é€£åˆå­¦ç¿’ã‚’æ¯”è¼ƒã—ã¾ã™ï¼š
#   1. å¹³æ–‡ã§ã®é€£åˆå­¦ç¿’ï¼ˆPlain Federated Learningï¼‰
#   2. CKKSæº–åŒå‹æš—å·ã‚’ä½¿ç”¨ã—ãŸé€£åˆå­¦ç¿’ï¼ˆEncrypted Federated Learningï¼‰
#
# ã€ä¸»è¦ãªç‰¹å¾´ã€‘
#   - OpenFHE CKKSãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ãŸæº–åŒå‹æš—å·åŒ–
#   - å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ¢ãƒ‡ãƒ«é‡ã¿ã‚’æš—å·åŒ–ã—ãŸã¾ã¾é›†ç´„å¯èƒ½
#   - CIFAR-10ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å®Ÿéš›ã®ç”»åƒåˆ†é¡ã‚’å®Ÿè¡Œ
#   - å¹³æ–‡ã¨æš—å·åŒ–ã®ç²¾åº¦ãƒ»å®Ÿè¡Œæ™‚é–“ã‚’æ¯”è¼ƒ
#
# ã€å‡¦ç†ã®æµã‚Œã€‘
#   1. ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™ã¨ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé–“ã§ã®åˆ†å‰²
#   2. å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
#   3. ã‚µãƒ¼ãƒãŒå„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ¢ãƒ‡ãƒ«ã‚’é›†ç´„ï¼ˆå¹³æ–‡ or æš—å·åŒ–ï¼‰
#   4. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è©•ä¾¡
#   5. çµæœã®å¯è¦–åŒ–ã¨ã‚µãƒãƒªãƒ¼å‡ºåŠ›
#
# =========================================================

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import threading
import time
import copy
from math import log2, ceil
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')  # GUIãªã—ç’°å¢ƒå¯¾å¿œ
import argparse
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns

# [OPENFHE-CKKS] è¿½åŠ 
from openfhe import *


# =========================
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# =========================
def _next_pow2(n: int) -> int:
    """
    ä¸ãˆã‚‰ã‚ŒãŸæ•°å€¤nä»¥ä¸Šã®æœ€å°ã®2ã®ç´¯ä¹—ã‚’è¿”ã™
    CKKSæš—å·åŒ–ã®ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯2ã®ç´¯ä¹—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ãŸã‚ä½¿ç”¨

    ä¾‹: n=100 â†’ 128, n=1000 â†’ 1024
    """
    return 1 << ceil(log2(max(1, n)))


# =========================================================
# ğŸ”’ CKKSæº–åŒå‹æš—å·ã‚’ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«é›†ç´„ã‚¯ãƒ©ã‚¹
# =========================================================
# ã€å½¹å‰²ã€‘
# è¤‡æ•°ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰é€ã‚‰ã‚Œã¦ããŸãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ã€æš—å·åŒ–ã—ãŸã¾ã¾å¹³å‡åŒ–ã™ã‚‹
#
# ã€å‡¦ç†ãƒ•ãƒ­ãƒ¼ã€‘
#   1. ã‚µãƒ¼ãƒå´ã§æš—å·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨éµãƒšã‚¢ã‚’ç”Ÿæˆï¼ˆåˆæœŸåŒ–æ™‚ï¼‰
#   2. å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®é‡ã¿ã‚’ãƒ¬ã‚¤ãƒ¤ã”ã¨ã«æš—å·åŒ–
#   3. æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾åŠ ç®—ï¼ˆEvalAddï¼‰
#   4. å¹³å‡åŒ–ã®ãŸã‚ 1/N ã‚’ä¹—ç®—ï¼ˆEvalMultï¼‰
#   5. å¾©å·ã—ã¦å¹³å‡åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’å–å¾—
#
# ã€CKKSæš—å·ã®ç‰¹å¾´ã€‘
#   - æµ®å‹•å°æ•°ç‚¹æ•°ã®è¿‘ä¼¼è¨ˆç®—ãŒå¯èƒ½ãªæº–åŒå‹æš—å·æ–¹å¼
#   - æš—å·åŒ–ã•ã‚ŒãŸã¾ã¾åŠ ç®—ãƒ»ä¹—ç®—ãŒå¯èƒ½
#   - ãƒãƒƒãƒå‡¦ç†ã«ã‚ˆã‚Šè¤‡æ•°ã®å€¤ã‚’ä¸€ã¤ã®æš—å·æ–‡ã§æ‰±ãˆã‚‹
# =========================================================
class FHEModelAggregator:
    """
    å½¹å‰²:
      - å„ãƒ¬ã‚¤ãƒ¤é‡ã¿ã®å½¢çŠ¶ã‚’è¨˜éŒ²
      - CKKSã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ 1 ã¤æº–å‚™ï¼ˆBatchSize ã¯æœ€å¤§è¦ç´ æ•°ã«åˆã‚ã›ã‚‹ï¼‰
      - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé‡ã¿ã‚’ãƒ¬ã‚¤ãƒ¤ã”ã¨ã« flatten â†’ CKKS ã§ pack & encrypt
      - ã‚µãƒ¼ãƒå´ã§æš—å·åŠ ç®— & å®šæ•°ä¹—ç®—ï¼ˆ1/num_clientsï¼‰â†’ å¾©å· â†’ å½¢çŠ¶ã«æˆ»ã—ã¦è¿”ã™
    """

    def __init__(
        self,
        model_structure,
        num_clients=5,
        # ä»¥ä¸‹2ã¤ã¯ Concrete-ML ç‰ˆã®æ®‹ç½®å¼•æ•°ï¼ˆå¤–éƒ¨ã‚¤ãƒ³ã‚¿ãƒ•ã‚§ãƒ¼ã‚¹ç¶­æŒã®ãŸã‚å—ã‘å–ã‚‹ãŒç„¡è¦–ï¼‰
        scale_factor=100,
        max_value=50,
        # CKKS æš—å·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        mult_depth: int = 1,           # ä¹—ç®—æ·±åº¦ï¼ˆåŠ ç®—ã¨å®šæ•°ä¹—ç®—ã®ã¿ãªã®ã§1ã§ååˆ†ï¼‰
        scale_mod_size: int = 50,      # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ä¿‚æ•°ã®ãƒ“ãƒƒãƒˆæ•°ï¼ˆç²¾åº¦ã«å½±éŸ¿ï¼‰
        security_level: SecurityLevel = SecurityLevel.HEStd_128_classic,  # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«
        bn_mode: str = 'fedavg',       # 'fedavg' or 'fedbn'
    ):
        self.num_clients = num_clients
        self.bn_mode = bn_mode

        # ========================================
        # ã‚¹ãƒ†ãƒƒãƒ—1: ãƒ¢ãƒ‡ãƒ«æ§‹é€ ã®è§£æ
        # ========================================
        # ãƒ¢ãƒ‡ãƒ«ã‹ã‚‰ã€Œæµ®å‹•å°æ•°ã®ã¿ã€ã®å½¢çŠ¶ã‚’åé›†ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‹BNç­‰ã®floatãƒãƒƒãƒ•ã‚¡ï¼‰
        self.weight_shapes = {}  # name -> torch.Size
        max_elems = 0  # æœ€å¤§è¦ç´ æ•°ã‚’è¨˜éŒ²ï¼ˆãƒãƒƒãƒã‚µã‚¤ã‚ºæ±ºå®šã«ä½¿ç”¨ï¼‰

        for name, param in model_structure.named_parameters():
            self.weight_shapes[name] = param.shape
            max_elems = max(max_elems, int(np.prod(param.shape)))

        for name, buffer in model_structure.named_buffers():
            if hasattr(buffer, "dtype") and buffer.dtype.is_floating_point:
                if self.bn_mode == 'fedbn' and (name.endswith('running_mean') or name.endswith('running_var')):
                    continue  # FedBN: é›†ç´„å¯¾è±¡ã‹ã‚‰é™¤å¤–
                self.weight_shapes[name] = buffer.shape
                max_elems = max(max_elems, int(np.prod(buffer.shape)))

        # ========================================
        # ã‚¹ãƒ†ãƒƒãƒ—2: CKKSæš—å·ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®è¨­å®š
        # ========================================
        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã¯2ã®ç´¯ä¹—ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚‹ï¼ˆCKKSæš—å·ã®ä»•æ§˜ï¼‰
        # ã¾ãŸã€ãƒªãƒ³ã‚°ã‚µã‚¤ã‚ºã®åŠåˆ†ä»¥ä¸‹ã«åˆ¶é™ã•ã‚Œã‚‹
        desired_batch_size = _next_pow2(max_elems)

        # CKKSæš—å·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¨­å®š
        params = CCParamsCKKSRNS()
        params.SetMultiplicativeDepth(mult_depth)     # ä¹—ç®—ã®æ·±ã•ï¼ˆå’Œã¨å®šæ•°ä¹—ç®—ã®ã¿ãªã®ã§1ï¼‰
        params.SetScalingModSize(scale_mod_size)      # ç²¾åº¦ã‚’æ±ºå®šã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        params.SetSecurityLevel(security_level)        # ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ¬ãƒ™ãƒ«ï¼ˆ128ãƒ“ãƒƒãƒˆï¼‰

        # ä¸€æ™‚çš„ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆã—ã¦ãƒªãƒ³ã‚°ã‚µã‚¤ã‚ºã‚’ç¢ºèª
        temp_cc = GenCryptoContext(params)
        ring_dim = temp_cc.GetRingDimension()         # ãƒªãƒ³ã‚°å¤šé …å¼ã®æ¬¡å…ƒ
        max_batch_size = ring_dim // 2                 # ãƒãƒƒãƒã‚µã‚¤ã‚ºã®ä¸Šé™

        # ãƒãƒƒãƒã‚µã‚¤ã‚ºã‚’åˆ¶ç´„å†…ã«èª¿æ•´
        self.batch_size = min(desired_batch_size, max_batch_size)
        print(f"ğŸ” CKKS parameters: desired_batch_size={desired_batch_size}, ring_dim={ring_dim}, max_batch_size={max_batch_size}")
        print(f"ğŸ” Using batch_size={self.batch_size}")

        # ========================================
        # ã‚¹ãƒ†ãƒƒãƒ—3: æš—å·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã¨éµã®ç”Ÿæˆ
        # ========================================
        # å®Ÿéš›ã«ä½¿ç”¨ã™ã‚‹ãƒãƒƒãƒã‚µã‚¤ã‚ºã§æš—å·ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
        params.SetBatchSize(self.batch_size)
        self.cc = GenCryptoContext(params)
        # å¿…è¦ãªæ©Ÿèƒ½ã®ã¿æœ‰åŠ¹åŒ–ï¼ˆå®šæ•°ä¹—ç®—ï¼‹åŠ ç®—ã®ã¿ï¼‰
        self.cc.Enable(PKESchemeFeature.PKE)
        self.cc.Enable(PKESchemeFeature.LEVELEDSHE)

        # éµç”Ÿæˆï¼ˆEvalMultKeyGen ã¯ä½¿ã‚ãªã„ï¼‰
        self.keys = self.cc.KeyGen()

        print(f"ğŸ” CKKS ready: ring dimension = {self.cc.GetRingDimension()}, batch_size = {self.batch_size}")

        self.decrypt_calls = 0
        # äº’æ›ãƒ€ãƒŸãƒ¼ï¼ˆæœªä½¿ç”¨ï¼‰
        self.circuits = {}

    def get_public_key(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæš—å·åŒ–ç”¨ã®å…¬é–‹éµã‚’è¿”ã™ã€‚"""
        return self.keys.publicKey

    # ï¼ˆã‚µãƒ¼ãƒå´æš—å·åŒ–APIã¯å»ƒæ­¢ï¼šã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§æš—å·åŒ–ã™ã‚‹ï¼‰

    def aggregate_encrypted_models(self, enc_payloads, bn_mode='fedavg'):
        """
        ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§æš—å·åŒ–ã•ã‚ŒãŸé‡ã¿ã‚’æš—å·é ˜åŸŸã®ã¾ã¾åŠ é‡å¹³å‡ã—ã€å¾©å·ã—ã¦è¿”ã™ã€‚

        enc_payloads: List of tuples (encrypted_state_dict, int_buffers_plain, sample_count)
                      encrypted_state_dict: {name: [Ciphertext,...]}  â€»floaté …ç›®ã®ã¿
                      int_buffers_plain: {name: torch.Tensor(intç³»)}   â€»å…ˆé ­ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’æ¡ç”¨
        bn_mode: 'fedavg' or 'fedbn'
                 'fedbn'ã®å ´åˆã€BNã®running_mean/running_varã¯é›†ç´„ã›ãšå…ˆé ­ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®å€¤ã‚’ä½¿ç”¨

        Returns:
            aggregated_weights: {name: torch.Tensor(float32)}ï¼ˆfloatãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‹floatãƒãƒƒãƒ•ã‚¡ï¼‰
            first_int_buffers:  {name: torch.Tensor(int)}ï¼ˆæ•´æ•°ãƒãƒƒãƒ•ã‚¡ã¯ã‚³ãƒ”ãƒ¼ï¼‰
        """
        print("\nğŸ”’ Starting CKKS model aggregation (client-side encryption)...")
        self.decrypt_calls = 0
        total_samples = sum(n for _, __, n in enc_payloads)
        weights = [n / total_samples for _, __, n in enc_payloads]
        num_clients = len(enc_payloads)

        aggregated_weights = {}
        # æ•´æ•°ãƒãƒƒãƒ•ã‚¡ã¯å…ˆé ­ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚‚ã®ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆè¦ä»¶ï¼‰
        first_int_buffers = enc_payloads[0][1]

        for name, shape in self.weight_shapes.items():
            # weight_shapes ã«ã¯æ—¢ã« running_* ãŒå…¥ã£ã¦ã„ãªã„ï¼ˆFedBNæ™‚ï¼‰
            num_elems = int(np.prod(shape))
            num_chunks = ceil(num_elems / self.batch_size)

            flat_vals = []
            for chunk_idx in range(num_chunks):
                c_sum = None
                for ci in range(num_clients):
                    enc_state = enc_payloads[ci][0]
                    w_i = weights[ci]
                    ct = enc_state[name][chunk_idx]
                    pt_w = self.cc.MakeCKKSPackedPlaintext([w_i] * self.batch_size)
                    term = self.cc.EvalMult(ct, pt_w)
                    c_sum = term if c_sum is None else self.cc.EvalAdd(c_sum, term)

                pt = self.cc.Decrypt(self.keys.secretKey, c_sum)
                pt.SetLength(self.batch_size)
                vals = getattr(pt, "GetRealPackedValue", pt.GetCKKSPackedValue)()
                flat_vals.extend(vals)
                self.decrypt_calls += 1

            trimmed = np.array(flat_vals[:num_elems], dtype=np.float64).reshape(tuple(shape))
            aggregated_weights[name] = torch.from_numpy(trimmed)

        # æœŸå¾…å¾©å·å›æ•°ãƒã‚§ãƒƒã‚¯ï¼ˆper-chunkï¼‰
        expected = sum(ceil(int(np.prod(s)) / self.batch_size) for s in self.weight_shapes.values())
        assert self.decrypt_calls == expected, f"decrypt_calls={self.decrypt_calls} != expected={expected}"
        print(f"[CKKS] decrypt_calls={self.decrypt_calls} (per-chunk, bn_mode={bn_mode})")
        return aggregated_weights, first_int_buffers


# =========================================================
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¨ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆCIFAR-10ç”»åƒåˆ†é¡ï¼‰
# =========================================================

from torchvision import datasets, transforms
from torch.utils.data import Subset
import random


def build_transforms():
    """
    CIFAR-10ç”¨ã®ãƒ‡ãƒ¼ã‚¿å¤‰æ›ï¼ˆå‰å‡¦ç†ï¼‰ã‚’ä½œæˆ

    ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã€‘
    - RandomHorizontalFlip: å·¦å³åè»¢ã§ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
    - RandomCrop: ãƒ©ãƒ³ãƒ€ãƒ ã‚¯ãƒ­ãƒƒãƒ—ã§ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µ
    - ToTensor: PILç”»åƒã‚’ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
    - Normalize: å¹³å‡ã¨æ¨™æº–åå·®ã§æ­£è¦åŒ–ï¼ˆCIFAR-10ã®çµ±è¨ˆå€¤ã‚’ä½¿ç”¨ï¼‰

    ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã€‘
    - ãƒ‡ãƒ¼ã‚¿æ‹¡å¼µãªã—ã€æ­£è¦åŒ–ã®ã¿
    """
    train_transform = transforms.Compose([
        transforms.RandomHorizontalFlip(),  # 50%ã®ç¢ºç‡ã§å·¦å³åè»¢
        transforms.RandomCrop(32, padding=4),  # 4ãƒ”ã‚¯ã‚»ãƒ«ãƒ‘ãƒ‡ã‚£ãƒ³ã‚°å¾Œã€32x32ã«ã‚¯ãƒ­ãƒƒãƒ—
        transforms.ToTensor(),  # [0,255]ã®ç”»åƒã‚’[0,1]ã®ãƒ†ãƒ³ã‚½ãƒ«ã«å¤‰æ›
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),  # CIFAR-10ã®çµ±è¨ˆå€¤
    ])
    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])
    return train_transform, test_transform


def iid_partition(indices, num_clients, seed):
    """
    IIDï¼ˆç‹¬ç«‹åŒåˆ†å¸ƒï¼‰ãƒ‡ãƒ¼ã‚¿åˆ†å‰²

    ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚·ãƒ£ãƒƒãƒ•ãƒ«ã—ã¦å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«å‡ç­‰ã«åˆ†é…
    å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯å…¨ã‚¯ãƒ©ã‚¹ã‚’ãƒãƒ©ãƒ³ã‚¹ã‚ˆãæŒã¤

    Args:
        indices: ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ
        num_clients: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°
        seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰

    Returns:
        å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ
    """
    rng = np.random.default_rng(seed)
    shuffled = np.array(indices)
    rng.shuffle(shuffled)
    splits = np.array_split(shuffled, num_clients)
    return [split.tolist() for split in splits]


def dirichlet_partition(labels, num_clients, alpha, seed):
    """
    Dirichletåˆ†å¸ƒã‚’ä½¿ç”¨ã—ãŸnon-IIDï¼ˆéç‹¬ç«‹åŒåˆ†å¸ƒï¼‰ãƒ‡ãƒ¼ã‚¿åˆ†å‰²

    å®Ÿä¸–ç•Œã®é€£åˆå­¦ç¿’ã‚’æ¨¡æ“¬ã™ã‚‹ãŸã‚ã€å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ãƒ‡ãƒ¼ã‚¿åˆ†å¸ƒã‚’åã‚‰ã›ã‚‹
    alphaãŒå°ã•ã„ã»ã©åã‚ŠãŒå¤§ãããªã‚‹ï¼ˆæ¥µç«¯ãªå ´åˆã€å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¯ç‰¹å®šã‚¯ãƒ©ã‚¹ã®ã¿æŒã¤ï¼‰

    ã€Dirichletåˆ†å¸ƒã¨ã¯ã€‘
    - ç¢ºç‡åˆ†å¸ƒã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ç”Ÿæˆã™ã‚‹åˆ†å¸ƒ
    - alphaãŒå°ã•ã„â†’ä¸å‡ä¸€ãªåˆ†å¸ƒï¼ˆä¸€éƒ¨ã®ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«åã‚‹ï¼‰
    - alphaãŒå¤§ãã„â†’å‡ä¸€ãªåˆ†å¸ƒï¼ˆIIDã«è¿‘ã¥ãï¼‰

    Args:
        labels: å…¨ãƒ‡ãƒ¼ã‚¿ã®ãƒ©ãƒ™ãƒ«é…åˆ—
        num_clients: ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆæ•°
        alpha: Dirichletãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆå°ã•ã„ã»ã©ä¸å‡ä¸€ï¼‰
        seed: ä¹±æ•°ã‚·ãƒ¼ãƒ‰

    Returns:
        å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãƒªã‚¹ãƒˆ
    """
    rng = np.random.default_rng(seed)
    labels = np.array(labels)
    client_indices = [[] for _ in range(num_clients)]
    num_classes = int(labels.max()) + 1

    # ã‚¯ãƒ©ã‚¹ã”ã¨ã«å‡¦ç†
    for class_idx in range(num_classes):
        # ã“ã®ã‚¯ãƒ©ã‚¹ã«å±ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—
        class_mask = labels == class_idx
        class_indices = np.where(class_mask)[0]
        rng.shuffle(class_indices)

        # Dirichletåˆ†å¸ƒã§å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã¸ã®å‰²ã‚Šå½“ã¦æ¯”ç‡ã‚’æ±ºå®š
        proportions = rng.dirichlet(np.full(num_clients, alpha))
        proportions = (np.cumsum(proportions) * len(class_indices)).astype(int)[:-1]
        splits = np.split(class_indices, proportions)

        # å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ãƒ‡ãƒ¼ã‚¿ã‚’å‰²ã‚Šå½“ã¦
        for client_id, split in enumerate(splits):
            client_indices[client_id].extend(split.tolist())

    # å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå†…ã§ã‚·ãƒ£ãƒƒãƒ•ãƒ«
    for client_id in range(num_clients):
        rng.shuffle(client_indices[client_id])

    return client_indices


class SimpleCIFARNet(nn.Module):
    """
    CIFAR-10ç”»åƒåˆ†é¡ç”¨ã®CNNãƒ¢ãƒ‡ãƒ«

    ã€ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ ã€‘
    - å…¥åŠ›: 32x32x3ï¼ˆRGBç”»åƒï¼‰
    - ç‰¹å¾´æŠ½å‡ºéƒ¨ï¼ˆfeaturesï¼‰:
        * Convå±¤(32ch) â†’ BatchNorm â†’ ReLU â†’ Convå±¤(32ch) â†’ BatchNorm â†’ ReLU â†’ MaxPool
        * Convå±¤(64ch) â†’ BatchNorm â†’ ReLU â†’ Convå±¤(64ch) â†’ BatchNorm â†’ ReLU â†’ MaxPool
        * Dropout(0.3)
    - åˆ†é¡éƒ¨ï¼ˆclassifierï¼‰:
        * Flatten â†’ å…¨çµåˆå±¤(256) â†’ ReLU â†’ Dropout(0.4) â†’ å…¨çµåˆå±¤(10)
    - å‡ºåŠ›: 10ã‚¯ãƒ©ã‚¹ï¼ˆCIFAR-10ã®ã‚¯ãƒ©ã‚¹æ•°ï¼‰

    ã€CIFAR-10ã®ã‚¯ãƒ©ã‚¹ã€‘
    0: airplane, 1: automobile, 2: bird, 3: cat, 4: deer,
    5: dog, 6: frog, 7: horse, 8: ship, 9: truck
    """

    def __init__(self):
        super(SimpleCIFARNet, self).__init__()

        # ç‰¹å¾´æŠ½å‡ºéƒ¨ï¼ˆç•³ã¿è¾¼ã¿å±¤ï¼‰
        self.features = nn.Sequential(
            # ç¬¬1ãƒ–ãƒ­ãƒƒã‚¯: 32x32x3 â†’ 32x32x32 â†’ 16x16x32
            nn.Conv2d(3, 32, kernel_size=3, padding=1),  # 3ãƒãƒ£ãƒ³ãƒãƒ«â†’32ãƒãƒ£ãƒ³ãƒãƒ«
            nn.BatchNorm2d(32),  # ãƒãƒƒãƒæ­£è¦åŒ–ï¼ˆå­¦ç¿’ã‚’å®‰å®šåŒ–ï¼‰
            nn.ReLU(inplace=True),  # æ´»æ€§åŒ–é–¢æ•°
            nn.Conv2d(32, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 2x2ãƒ—ãƒ¼ãƒªãƒ³ã‚°ï¼ˆã‚µã‚¤ã‚ºåŠæ¸›ï¼‰

            # ç¬¬2ãƒ–ãƒ­ãƒƒã‚¯: 16x16x32 â†’ 16x16x64 â†’ 8x8x64
            nn.Conv2d(32, 64, kernel_size=3, padding=1),  # 32ãƒãƒ£ãƒ³ãƒãƒ«â†’64ãƒãƒ£ãƒ³ãƒãƒ«
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, 64, kernel_size=3, padding=1),
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.MaxPool2d(2),  # 8x8ã¾ã§ç¸®å°
            nn.Dropout(0.3),  # éå­¦ç¿’é˜²æ­¢
        )

        # åˆ†é¡éƒ¨ï¼ˆå…¨çµåˆå±¤ï¼‰
        self.classifier = nn.Sequential(
            nn.Flatten(),  # 8x8x64 = 4096 â†’ 1æ¬¡å…ƒã«å¹³å¦åŒ–
            nn.Linear(64 * 8 * 8, 256),  # 4096 â†’ 256
            nn.ReLU(inplace=True),
            nn.Dropout(0.4),  # éå­¦ç¿’é˜²æ­¢
            nn.Linear(256, 10),  # 256 â†’ 10ã‚¯ãƒ©ã‚¹ï¼ˆæœ€çµ‚å‡ºåŠ›ï¼‰
        )

    def forward(self, x):
        """
        é †ä¼æ’­å‡¦ç†

        Args:
            x: å…¥åŠ›ç”»åƒãƒ†ãƒ³ã‚½ãƒ« (batch_size, 3, 32, 32)

        Returns:
            å„ã‚¯ãƒ©ã‚¹ã®ã‚¹ã‚³ã‚¢ (batch_size, 10)
        """
        x = self.features(x)  # ç‰¹å¾´æŠ½å‡º
        return self.classifier(x)  # åˆ†é¡


def build_client_loaders(dataset, num_clients, batch_size, iid, alpha, seed):
    """å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚’ä½œæˆ"""
    indices = list(range(len(dataset)))
    if iid:
        partitions = iid_partition(indices, num_clients, seed)
    else:
        partitions = dirichlet_partition(dataset.targets, num_clients, alpha, seed)

    client_loaders = []
    for partition in partitions:
        subset = Subset(dataset, partition)
        loader = DataLoader(
            subset,
            batch_size=batch_size,
            shuffle=True,
            num_workers=2,
            pin_memory=torch.cuda.is_available(),
        )
        client_loaders.append(loader)
    return client_loaders


class Client:
    """
    é€£åˆå­¦ç¿’ã«ãŠã‘ã‚‹ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆå‚åŠ è€…ï¼‰

    ã€å½¹å‰²ã€‘
    - æ‰‹å…ƒã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’
    - å­¦ç¿’å¾Œã®é‡ã¿ã‚’ã‚µãƒ¼ãƒã«é€ä¿¡
    - ã‚µãƒ¼ãƒã‹ã‚‰å—ã‘å–ã£ãŸã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã§åˆæœŸåŒ–

    ã€é€£åˆå­¦ç¿’ã®æµã‚Œï¼ˆã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆè¦–ç‚¹ï¼‰ã€‘
    1. ã‚µãƒ¼ãƒã‹ã‚‰ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’å—ä¿¡
    2. è‡ªåˆ†ã®ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
    3. è¨“ç·´å¾Œã®é‡ã¿ã‚’ã‚µãƒ¼ãƒã«é€ä¿¡
    4. æ¬¡ã®ãƒ©ã‚¦ãƒ³ãƒ‰ã¾ã§å¾…æ©Ÿ
    """
    def __init__(self, client_id, train_loader, device, lr=0.01, momentum=0.9, weight_decay=5e-4):
        self.client_id = client_id  # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆID
        self.device = device  # è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹ï¼ˆCPU or GPUï¼‰
        self.train_loader = train_loader  # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã®DataLoader
        self.lr = lr  # å­¦ç¿’ç‡
        self.momentum = momentum  # SGDã®ãƒ¢ãƒ¼ãƒ¡ãƒ³ã‚¿ãƒ 
        self.weight_decay = weight_decay  # é‡ã¿æ¸›è¡°ï¼ˆæ­£å‰‡åŒ–ï¼‰
        # æš—å·åŒ–ç”¨ã®ç›´è¿‘çŠ¶æ…‹
        self.last_state_floats = None   # {name: Tensor(float)}
        self.last_int_buffers = None    # {name: Tensor(int)}
        self.local_sample_count = 0
        # FedBN: ãƒ©ã‚¦ãƒ³ãƒ‰é–“ã§å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒè‡ªåˆ†ã®BNçµ±è¨ˆã‚’ä¿æŒã™ã‚‹ãŸã‚
        self.prev_bn_stats = {}  # {name: Tensor} for running_mean / running_var / num_batches_tracked

    def local_update(self, global_weights, epochs=1, bn_mode='fedavg'):
        """
        ãƒ­ãƒ¼ã‚«ãƒ«å­¦ç¿’ã‚’å®Ÿè¡Œ

        ã€å‡¦ç†ã®æµã‚Œã€‘
        1. ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã§ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
        2. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã§æŒ‡å®šã‚¨ãƒãƒƒã‚¯æ•°ã ã‘å­¦ç¿’
        3. å­¦ç¿’å¾Œã®é‡ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ•°ã‚’è¿”ã™

        Args:
            global_weights: ã‚µãƒ¼ãƒã‹ã‚‰å—ã‘å–ã£ãŸã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿
            epochs: ãƒ­ãƒ¼ã‚«ãƒ«å­¦ç¿’ã®ã‚¨ãƒãƒƒã‚¯æ•°
            bn_mode: 'fedavg' or 'fedbn' (ç¾åœ¨ã¯ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´ã§ã¯æœªä½¿ç”¨)

        Returns:
            (cpu_state, total_samples): å­¦ç¿’å¾Œã®é‡ã¿ã¨ãƒ‡ãƒ¼ã‚¿æ•°
        """
        print(f"Client {self.client_id}: Starting local update")

        # ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã§åˆæœŸåŒ–
        model = SimpleCIFARNet().to(self.device)
        if bn_mode == 'fedbn':
            # FedBN: running_mean/running_var ã¯ãƒ­ãƒ¼ãƒ‰ã›ãšã€å„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒç‹¬è‡ªã®çµ±è¨ˆé‡ã‚’ä¿æŒ
            filtered = {k: v for k, v in global_weights.items()
                        if not (k.endswith('running_mean') or k.endswith('running_var'))}
            model.load_state_dict(filtered, strict=False)
            # â˜… å‰ãƒ©ã‚¦ãƒ³ãƒ‰ã®è‡ªåˆ†ã®BNçµ±è¨ˆã‚’å¾©å…ƒï¼ˆä¿æŒâ†’å¾©å…ƒï¼‰
            if self.prev_bn_stats:
                with torch.no_grad():
                    msd = model.state_dict()
                    for k, v in self.prev_bn_stats.items():
                        if k in msd:
                            msd[k].copy_(v.to(msd[k].dtype))
                    model.load_state_dict(msd, strict=False)
        else:
            model.load_state_dict(global_weights)
        model.train()  # è¨“ç·´ãƒ¢ãƒ¼ãƒ‰

        # ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ï¼ˆSGD: ç¢ºç‡çš„å‹¾é…é™ä¸‹æ³•ï¼‰
        optimizer = optim.SGD(
            model.parameters(),
            lr=self.lr,
            momentum=self.momentum,  # ãƒ¢ãƒ¼ãƒ¡ãƒ³ã‚¿ãƒ ã§åæŸã‚’å®‰å®šåŒ–
            weight_decay=self.weight_decay,  # L2æ­£å‰‡åŒ–
        )
        # æå¤±é–¢æ•°ï¼ˆã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼: å¤šã‚¯ãƒ©ã‚¹åˆ†é¡ã®æ¨™æº–ï¼‰
        criterion = nn.CrossEntropyLoss()

        # ãƒ­ãƒ¼ã‚«ãƒ«ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’
        total_loss = 0.0
        total_samples = 0
        for _ in range(epochs):
            for inputs, targets in self.train_loader:
                # ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒã‚¤ã‚¹ã«è»¢é€
                inputs = inputs.to(self.device)
                targets = targets.to(self.device)

                # å‹¾é…ã‚’ã‚¼ãƒ­ã‚¯ãƒªã‚¢
                optimizer.zero_grad(set_to_none=True)
                # é †ä¼æ’­
                outputs = model(inputs)
                # æå¤±è¨ˆç®—
                loss = criterion(outputs, targets)
                # é€†ä¼æ’­ï¼ˆå‹¾é…è¨ˆç®—ï¼‰
                loss.backward()
                # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
                optimizer.step()

                # çµ±è¨ˆæƒ…å ±ã®è¨˜éŒ²
                batch_size = inputs.size(0)
                total_loss += loss.item() * batch_size
                total_samples += batch_size

        avg_loss = total_loss / max(total_samples, 1)
        print(f"Client {self.client_id}: Completed training with loss={avg_loss:.4f}")

        # å­¦ç¿’å¾Œã®é‡ã¿ã‚’CPUã¸
        cpu_state = {k: v.detach().cpu() for k, v in model.state_dict().items()}
        # æµ®å‹•å°æ•°é …ç›®ã¨æ•´æ•°ãƒãƒƒãƒ•ã‚¡ã‚’åˆ†é›¢ä¿å­˜ï¼ˆæš—å·åŒ–/ã‚³ãƒ”ãƒ¼æ–¹é‡ï¼‰
        self.last_state_floats = {k: t for k, t in cpu_state.items() if t.dtype.is_floating_point}
        self.last_int_buffers  = {k: t for k, t in cpu_state.items() if not t.dtype.is_floating_point}
        self.local_sample_count = total_samples

        # â˜… FedBN: æ¬¡ãƒ©ã‚¦ãƒ³ãƒ‰ç”¨ã«è‡ªåˆ†ã®BNçµ±è¨ˆã‚’ä¿æŒ
        if bn_mode == 'fedbn':
            self.prev_bn_stats = {
                k: t.clone()
                for k, t in cpu_state.items()
                if (k.endswith('running_mean') or k.endswith('running_var') or k.endswith('num_batches_tracked'))
            }
        return cpu_state, total_samples

    def encrypt_for_server(self, aggregator):
        """
        ç›´è¿‘ã®floaté …ç›®ã®ã¿CKKSã§ãƒãƒ£ãƒ³ã‚¯æš—å·åŒ–ã—ã¦è¿”ã™ã€‚
        æˆ»ã‚Šå€¤: (enc_float_state, int_buffers_plain, sample_count)
        """
        pk = aggregator.get_public_key()
        cc = aggregator.cc
        L = aggregator.batch_size
        enc = {}
        # aggregator.weight_shapes ã¯ã€Œé›†ç´„å¯¾è±¡ã® float é …ç›®ã€ã ã‘ï¼ˆFedBNãªã‚‰ running_* ã‚’å«ã¾ãªã„ï¼‰
        for name in aggregator.weight_shapes.keys():
            tensor = self.last_state_floats[name]
            flat = tensor.numpy().astype(np.float64).ravel()
            chunks = []
            for i in range(0, len(flat), L):
                piece = flat[i:i+L]
                if len(piece) < L:
                    piece = np.pad(piece, (0, L - len(piece)), constant_values=0.0)
                chunks.append(cc.Encrypt(pk, cc.MakeCKKSPackedPlaintext(piece.tolist())))
            enc[name] = chunks
        return enc, self.last_int_buffers, self.local_sample_count


# =========================================================
# CKKSæš—å·åŒ–ã‚µãƒ¼ãƒ: ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã¨æš—å·åŒ–é›†ç´„
# =========================================================
class FHEServer:
    """
    CKKSæº–åŒå‹æš—å·ã‚’ä½¿ç”¨ã™ã‚‹é€£åˆå­¦ç¿’ã‚µãƒ¼ãƒ

    ã€å½¹å‰²ã€‘
    - ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®ä¿æŒã¨è©•ä¾¡
    - ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰å—ã‘å–ã£ãŸé‡ã¿ã‚’CKKSæš—å·åŒ–ã§é›†ç´„
    - ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼ã‚’ä¿è­·ã—ãªãŒã‚‰ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°

    ã€é€£åˆå­¦ç¿’ã®æµã‚Œï¼ˆã‚µãƒ¼ãƒè¦–ç‚¹ï¼‰ã€‘
    1. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’åˆæœŸåŒ–
    2. å„ãƒ©ã‚¦ãƒ³ãƒ‰ã§ï¼š
       a. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®é‡ã¿ã‚’ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é…å¸ƒ
       b. ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰æ›´æ–°ã•ã‚ŒãŸé‡ã¿ã‚’å—ä¿¡
       c. CKKSæš—å·åŒ–ã§é‡ã¿ã‚’é›†ç´„ï¼ˆå¹³æ–‡ã‚’è¦‹ãšã«å¹³å‡åŒ–ï¼‰
       d. ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã‚’æ›´æ–°
       e. ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§è©•ä¾¡
    """
    def __init__(self, num_clients, test_loader, device, bn_mode='fedavg'):
        self.num_clients = num_clients
        self.device = device
        self.global_model = SimpleCIFARNet().to(self.device)
        self.bn_mode = bn_mode

        # [REPLACED WITH OPENFHE-CKKS] ã“ã“ã§ CKKS ç‰ˆã® Aggregator ã‚’ä½¿ç”¨
        self.fhe_aggregator = FHEModelAggregator(
            self.global_model,
            num_clients=num_clients,
            scale_factor=100,   # å¼•æ•°äº’æ›ã®ãŸã‚å—ã‘æ¸¡ã—ã¯ã™ã‚‹ãŒã€CKKS ç‰ˆã§ã¯æœªä½¿ç”¨
            max_value=50,       # åŒä¸Š
            bn_mode=bn_mode
        )

        self.test_loader = test_loader
        self.criterion = nn.CrossEntropyLoss()

    def evaluate_global_model(self):
        """ã‚µãƒ¼ãƒã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è©•ä¾¡"""
        self.global_model.eval()
        correct = 0
        total = 0
        total_loss = 0.0
        with torch.no_grad():
            for data, target in self.test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.global_model(data)
                loss = self.criterion(output, target)
                predicted = torch.argmax(output, dim=1)
                correct += (predicted == target).sum().item()
                total += target.size(0)
                total_loss += loss.item()
        accuracy = correct / total * 100
        avg_loss = total_loss / len(self.test_loader)
        print(f"Global Model - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")
        return accuracy, avg_loss

    def aggregate_models_with_fhe(self, enc_payloads, bn_mode='fedavg'):
        """
        ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´æš—å·åŒ–æ¸ˆã¿ãƒšã‚¤ãƒ­ãƒ¼ãƒ‰ã‚’å—ã‘å–ã‚Šã€æš—å·åŠ é‡å¹³å‡â†’å¾©å·â†’é©ç”¨ã€‚
        enc_payloads: list of (encrypted_float_state, int_buffers_plain, num_samples)
        bn_mode: 'fedavg' or 'fedbn'
        """
        print("ğŸ”’ FHE-based model aggregation (OpenFHE CKKS, client-side encryption)...")
        agg_float_state, int_buffers = self.fhe_aggregator.aggregate_encrypted_models(enc_payloads, bn_mode=bn_mode)
        state = self.global_model.state_dict()
        # floaté …ç›®ï¼ˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼‹BN running_mean/varï¼‰ã‚’æ›´æ–°
        for name, tensor in agg_float_state.items():
            state[name] = tensor
        # æ•´æ•°ãƒãƒƒãƒ•ã‚¡ã¯å…ˆé ­ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‹ã‚‰ã‚³ãƒ”ãƒ¼
        for name, tensor in int_buffers.items():
            state[name] = tensor
        self.global_model.load_state_dict(state, strict=False)
        print(f"ğŸ”’ FHE Global model updated (weighted avg for floats, integer buffers copied, bn_mode={bn_mode})")

    def get_global_weights(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é…å¸ƒã™ã‚‹ãŸã‚ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã‚’è¿”ã™"""
        return copy.deepcopy(self.global_model.state_dict())


# =========================================================
# å¹³æ–‡ã‚µãƒ¼ãƒ: æš—å·åŒ–ãªã—ã®é€šå¸¸ã®é€£åˆå­¦ç¿’
# =========================================================
class PlainServer:
    """
    å½¹å‰²:
      - ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®ä¿æŒã¨è©•ä¾¡
      - å¹³æ–‡ã§ã®ãƒ¢ãƒ‡ãƒ«é›†ç´„ï¼ˆå˜ç´”å¹³å‡ï¼‰
    """
    def __init__(self, num_clients, test_loader, device):
        self.num_clients = num_clients
        self.device = device
        self.global_model = SimpleCIFARNet().to(self.device)
        self.test_loader = test_loader
        self.criterion = nn.CrossEntropyLoss()

    def evaluate_global_model(self):
        """ã‚µãƒ¼ãƒã§ã‚°ãƒ­ãƒ¼ãƒãƒ«ãƒ¢ãƒ‡ãƒ«ã®ç²¾åº¦ã‚’è©•ä¾¡"""
        self.global_model.eval()
        correct = 0
        total = 0
        total_loss = 0.0
        with torch.no_grad():
            for data, target in self.test_loader:
                data, target = data.to(self.device), target.to(self.device)
                output = self.global_model(data)
                loss = self.criterion(output, target)
                predicted = torch.argmax(output, dim=1)
                correct += (predicted == target).sum().item()
                total += target.size(0)
                total_loss += loss.item()
        accuracy = correct / total * 100
        avg_loss = total_loss / len(self.test_loader)
        print(f"Global Model - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%")
        return accuracy, avg_loss

    def aggregate_models_plain(self, client_updates, bn_mode='fedavg'):
        """
        å¹³æ–‡ã§ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆé‡ã¿ã‚’å¹³å‡ã—ã€ã‚°ãƒ­ãƒ¼ãƒãƒ«ã¸é©ç”¨ã€‚
        client_updates: list of (state_dict, num_samples) tuples
        bn_mode: 'fedavg' or 'fedbn'
        """
        print(f"ğŸ“Š Plain model aggregation (weighted averaging, bn_mode={bn_mode})...")

        # ã‚µãƒ³ãƒ—ãƒ«æ•°ã«ã‚ˆã‚‹åŠ é‡å¹³å‡
        total_samples = sum(num_samples for _, num_samples in client_updates)
        aggregated_weights = {}

        state0 = client_updates[0][0]
        for layer_name in state0.keys():
            if bn_mode == 'fedbn' and (layer_name.endswith('running_mean') or layer_name.endswith('running_var')):
                # è§¦ã‚‰ãªã„ï¼ˆç¾ã‚°ãƒ­ãƒ¼ãƒãƒ«ã®å€¤ã‚’ä¿ã¤ï¼‰
                aggregated_weights[layer_name] = self.global_model.state_dict()[layer_name]
                continue
            # æ•´æ•°å‹ã®ãƒãƒƒãƒ•ã‚¡ï¼ˆnum_batches_trackedãªã©ï¼‰ã¯ã‚¹ã‚­ãƒƒãƒ—
            if state0[layer_name].dtype in [torch.int32, torch.int64, torch.long]:
                aggregated_weights[layer_name] = state0[layer_name].clone()
            else:
                # åŠ é‡å¹³å‡ã‚’è¨ˆç®—
                weighted_sum = torch.zeros_like(state0[layer_name])
                for state_dict, num_samples in client_updates:
                    weight = num_samples / total_samples
                    weighted_sum += state_dict[layer_name] * weight
                aggregated_weights[layer_name] = weighted_sum

        self.global_model.load_state_dict(aggregated_weights)
        print(f"ğŸ“Š Plain Global model updated (bn_mode={bn_mode})")

    def get_global_weights(self):
        """ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«é…å¸ƒã™ã‚‹ãŸã‚ã®ã‚°ãƒ­ãƒ¼ãƒãƒ«é‡ã¿ã‚’è¿”ã™"""
        return copy.deepcopy(self.global_model.state_dict())


# =========================================================
# æ¯”è¼ƒå®Ÿé¨“é–¢æ•°
# =========================================================
def run_federated_learning_comparison(
    num_clients=10,
    num_rounds=10,
    batch_size=64,
    local_epochs=1,
    lr=0.01,
    iid=True,
    alpha=0.5,
    seed=42,
    data_dir='./data',
    bn_mode='fedavg'
):
    """
    å¹³æ–‡ã¨CKKSæš—å·åŒ–ã®é€£åˆå­¦ç¿’ã‚’å®Ÿè¡Œã—ã€ç²¾åº¦ã¨æ™‚é–“ã‚’æ¯”è¼ƒ
    """
    print("="*80)
    print("ğŸ”¬ FEDERATED LEARNING COMPARISON: Plain vs CKKS Encrypted")
    print("="*80)

    # ã‚·ãƒ¼ãƒ‰è¨­å®š
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)

    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"Using device: {device}")

    # ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæº–å‚™
    train_transform, test_transform = build_transforms()
    train_dataset = datasets.CIFAR10(data_dir, train=True, download=True, transform=train_transform)
    test_dataset = datasets.CIFAR10(data_dir, train=False, download=True, transform=test_transform)

    # ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ä½œæˆ
    client_loaders = build_client_loaders(
        train_dataset,
        num_clients=num_clients,
        batch_size=batch_size,
        iid=iid,
        alpha=alpha,
        seed=seed,
    )

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
    test_loader = DataLoader(
        test_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=torch.cuda.is_available(),
    )

    # çµæœæ ¼ç´ç”¨
    results = {
        'plain': {'accuracy': [], 'time': []},
        'ckks': {'accuracy': [], 'time': [], 'key_gen_time': 0}
    }

    # =========================================================
    # 1. å¹³æ–‡ã§ã®é€£åˆå­¦ç¿’
    # =========================================================
    print("\n" + "="*80)
    print("ğŸ“Š PLAIN FEDERATED LEARNING")
    print("="*80)

    plain_server = PlainServer(num_clients=num_clients, test_loader=test_loader, device=device)
    plain_clients = [
        Client(client_id=i+1, train_loader=client_loaders[i], device=device, lr=lr)
        for i in range(num_clients)
    ]

    print("\nInitial Global Model Evaluation (Plain):")
    initial_accuracy_plain, _ = plain_server.evaluate_global_model()
    results['plain']['accuracy'].append(initial_accuracy_plain)

    for round_num in range(num_rounds):
        print(f"\n{'='*60}")
        print(f"ğŸ“Š PLAIN ROUND {round_num + 1}")
        print(f"{'='*60}")

        round_start = time.time()

        global_weights = plain_server.get_global_weights()
        client_updates = []

        for client in plain_clients:
            print(f"\n--- Client {client.client_id} Local Update ---")
            state_dict, num_samples = client.local_update(global_weights, epochs=local_epochs, bn_mode=bn_mode)
            client_updates.append((state_dict, num_samples))

        print(f"\n--- ğŸ“Š Plain Server Aggregation ---")
        plain_server.aggregate_models_plain(client_updates, bn_mode=bn_mode)

        round_end = time.time()
        round_time = round_end - round_start

        print(f"\nRound {round_num + 1} Global Model Evaluation (Plain):")
        current_accuracy, _ = plain_server.evaluate_global_model()

        results['plain']['accuracy'].append(current_accuracy)
        results['plain']['time'].append(round_time)

        print(f"ğŸ“Š Plain Round {round_num + 1} completed in {round_time:.2f} seconds!")

    # =========================================================
    # 2. CKKSæš—å·åŒ–ã§ã®é€£åˆå­¦ç¿’
    # =========================================================
    print("\n" + "="*80)
    print("ğŸ”’ CKKS ENCRYPTED FEDERATED LEARNING")
    print("="*80)

    # éµç”Ÿæˆæ™‚é–“ã‚’è¨ˆæ¸¬
    key_gen_start = time.time()
    ckks_server = FHEServer(num_clients=num_clients, test_loader=test_loader, device=device, bn_mode=bn_mode)
    key_gen_end = time.time()
    key_gen_time = key_gen_end - key_gen_start
    results['ckks']['key_gen_time'] = key_gen_time

    print(f"ğŸ”‘ Key generation time: {key_gen_time:.2f} seconds")

    ckks_clients = [
        Client(client_id=i+1, train_loader=client_loaders[i], device=device, lr=lr)
        for i in range(num_clients)
    ]

    print("\nInitial Global Model Evaluation (CKKS):")
    initial_accuracy_ckks, _ = ckks_server.evaluate_global_model()
    results['ckks']['accuracy'].append(initial_accuracy_ckks)

    for round_num in range(num_rounds):
        print(f"\n{'='*60}")
        print(f"ğŸ”’ CKKS ENCRYPTED ROUND {round_num + 1}")
        print(f"{'='*60}")

        round_start = time.time()

        global_weights = ckks_server.get_global_weights()
        enc_payloads = []

        for client in ckks_clients:
            print(f"\n--- Client {client.client_id} Local Update ---")
            state_dict, num_samples = client.local_update(global_weights, epochs=local_epochs, bn_mode=bn_mode)
            enc_payloads.append(client.encrypt_for_server(ckks_server.fhe_aggregator))

        print(f"\n--- ğŸ”’ CKKS Server Aggregation ---")
        ckks_server.aggregate_models_with_fhe(enc_payloads, bn_mode=bn_mode)

        round_end = time.time()
        round_time = round_end - round_start

        print(f"\nRound {round_num + 1} Global Model Evaluation (CKKS):")
        current_accuracy, _ = ckks_server.evaluate_global_model()

        results['ckks']['accuracy'].append(current_accuracy)
        results['ckks']['time'].append(round_time)

        print(f"ğŸ”’ CKKS Round {round_num + 1} completed in {round_time:.2f} seconds!")

    # è¨“ç·´ã•ã‚ŒãŸã‚µãƒ¼ãƒãƒ¼ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚‚è¿”ã™ï¼ˆè¦–è¦šçš„è¨¼æ˜ã®ãŸã‚ï¼‰
    return results, {'plain': plain_server, 'ckks': ckks_server}


def plot_comparison_results(results, num_rounds, num_clients):
    """
    æ¯”è¼ƒçµæœã‚’ã‚°ãƒ©ãƒ•åŒ–ã—ã¦ä¿å­˜
    """
    key_gen_time = results['ckks']['key_gen_time']

    # å›³ã®ä½œæˆ
    fig, axes = plt.subplots(2, 1, figsize=(12, 10))

    # ãƒ©ã‚¦ãƒ³ãƒ‰ç•ªå·ï¼ˆ0ã¯Initialã€1ä»¥é™ã¯å„ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
    rounds = list(range(num_rounds + 1))

    # =========================================================
    # 1. ç²¾åº¦ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•
    # =========================================================
    ax1 = axes[0]
    ax1.plot(rounds, results['plain']['accuracy'], 'o-', label='Plain', linewidth=2, markersize=8)
    ax1.plot(rounds, results['ckks']['accuracy'], 's-', label='CKKS Encrypted', linewidth=2, markersize=8)
    ax1.set_xlabel('Round', fontsize=12)
    ax1.set_ylabel('Accuracy (%)', fontsize=12)
    ax1.set_title('Federated Learning Accuracy Comparison: Plain vs CKKS', fontsize=14, fontweight='bold')
    ax1.legend(fontsize=11)
    ax1.grid(True, alpha=0.3)
    ax1.set_xticks(rounds)
    ax1.set_xticklabels(['Initial'] + [f'R{i}' for i in range(1, num_rounds + 1)])

    # =========================================================
    # 2. å®Ÿè¡Œæ™‚é–“ã®æ¯”è¼ƒã‚°ãƒ©ãƒ•
    # =========================================================
    ax2 = axes[1]
    round_nums = list(range(1, num_rounds + 1))

    bar_width = 0.35
    x = np.arange(len(round_nums))

    bars1 = ax2.bar(x - bar_width/2, results['plain']['time'], bar_width,
                    label='Plain', alpha=0.8)
    bars2 = ax2.bar(x + bar_width/2, results['ckks']['time'], bar_width,
                    label='CKKS Encrypted', alpha=0.8)

    ax2.set_xlabel('Round', fontsize=12)
    ax2.set_ylabel('Time (seconds)', fontsize=12)
    ax2.set_title('Federated Learning Execution Time Comparison: Plain vs CKKS', fontsize=14, fontweight='bold')
    ax2.set_xticks(x)
    ax2.set_xticklabels([f'Round {i}' for i in round_nums])
    ax2.legend(fontsize=11)
    ax2.grid(True, alpha=0.3, axis='y')

    # éµç”Ÿæˆæ™‚é–“ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§è¡¨ç¤º
    key_gen_text = f'CKKS Key Generation Time: {key_gen_time:.2f} seconds\n(Not included in round times)'
    ax2.text(0.02, 0.98, key_gen_text, transform=ax2.transAxes,
             fontsize=11, verticalalignment='top',
             bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

    plt.tight_layout()

    # ã‚°ãƒ©ãƒ•ã‚’ä¿å­˜
    output_file = f'federated_learning_comparison_clients{num_clients}_rounds{num_rounds}.png'
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\nğŸ“Š Comparison graph saved to: {output_file}")

    plt.close()


# =========================================================
# ğŸ¨ è¦–è¦šçš„è¨¼æ˜: ç”»åƒåˆ†é¡ãŒå®Ÿéš›ã«å‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’è¨¼æ˜
# =========================================================

def visualize_sample_predictions(model, test_dataset, device, num_samples=16, output_file='sample_predictions.png'):
    """
    ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’æŠ½å‡ºã—ã€äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–

    ã€ç›®çš„ã€‘
    ã“ã®ãƒ—ãƒ­ã‚°ãƒ©ãƒ ãŒãƒ€ãƒŸãƒ¼ã§ã¯ãªãã€å®Ÿéš›ã«ç”»åƒã‚’åˆ†é¡ã—ã¦ã„ã‚‹ã“ã¨ã‚’è¨¼æ˜

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        test_dataset: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        num_samples: è¡¨ç¤ºã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«æ•°
        output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    # CIFAR-10ã®ã‚¯ãƒ©ã‚¹å
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    model.eval()

    # ãƒ©ãƒ³ãƒ€ãƒ ã«ã‚µãƒ³ãƒ—ãƒ«ã‚’é¸æŠ
    indices = np.random.choice(len(test_dataset), num_samples, replace=False)

    fig, axes = plt.subplots(4, 4, figsize=(12, 12))
    fig.suptitle('ğŸ” Sample Image Classification Results (Proof of Real Classification)',
                 fontsize=14, fontweight='bold')

    for idx, ax in enumerate(axes.flat):
        if idx >= num_samples:
            break

        # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        img, true_label = test_dataset[indices[idx]]

        # äºˆæ¸¬
        with torch.no_grad():
            img_batch = img.unsqueeze(0).to(device)
            output = model(img_batch)
            pred_label = output.argmax(dim=1).item()
            confidence = torch.softmax(output, dim=1)[0][pred_label].item()

        # ç”»åƒã‚’æ­£è¦åŒ–è§£é™¤ã—ã¦è¡¨ç¤ºç”¨ã«å¤‰æ›
        img_display = img.cpu().numpy().transpose(1, 2, 0)
        mean = np.array([0.4914, 0.4822, 0.4465])
        std = np.array([0.2023, 0.1994, 0.2010])
        img_display = std * img_display + mean
        img_display = np.clip(img_display, 0, 1)

        # ç”»åƒã‚’è¡¨ç¤º
        ax.imshow(img_display)
        ax.axis('off')

        # æ­£è§£ãƒ»ä¸æ­£è§£ã§è‰²åˆ†ã‘
        color = 'green' if pred_label == true_label else 'red'
        title = f'True: {class_names[true_label]}\nPred: {class_names[pred_label]}\n({confidence*100:.1f}%)'
        ax.set_title(title, fontsize=9, color=color, fontweight='bold')

    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"\nğŸ¨ Sample predictions visualization saved to: {output_file}")
    plt.close()


def visualize_confusion_matrix(model, test_loader, device, output_file='confusion_matrix.png'):
    """
    æ··åŒè¡Œåˆ—ã‚’ç”Ÿæˆã—ã¦å¯è¦–åŒ–

    ã€æ··åŒè¡Œåˆ—ã¨ã¯ã€‘
    ç¸¦è»¸ãŒçœŸã®ãƒ©ãƒ™ãƒ«ã€æ¨ªè»¸ãŒäºˆæ¸¬ãƒ©ãƒ™ãƒ«ã®è¡Œåˆ—
    å¯¾è§’æˆåˆ†ãŒæ­£è§£ã€éå¯¾è§’æˆåˆ†ãŒèª¤åˆ†é¡ã‚’ç¤ºã™
    å®Ÿéš›ã«åˆ†é¡ãŒè¡Œã‚ã‚Œã¦ã„ã‚‹ã“ã¨ã®å¼·åŠ›ãªè¨¼æ‹ 

    Args:
        model: å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«
        test_loader: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        device: è¨ˆç®—ãƒ‡ãƒã‚¤ã‚¹
        output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«å
    """
    # CIFAR-10ã®ã‚¯ãƒ©ã‚¹å
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    model.eval()
    all_preds = []
    all_labels = []

    print("\nğŸ” Generating confusion matrix...")

    # å…¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
    with torch.no_grad():
        for data, labels in test_loader:
            data, labels = data.to(device), labels.to(device)
            outputs = model(data)
            preds = outputs.argmax(dim=1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    # æ··åŒè¡Œåˆ—ã‚’è¨ˆç®—
    cm = confusion_matrix(all_labels, all_preds)

    # å¯è¦–åŒ–
    fig, ax = plt.subplots(figsize=(12, 10))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, yticklabels=class_names,
                cbar_kws={'label': 'Number of samples'})
    ax.set_xlabel('Predicted Label', fontsize=12, fontweight='bold')
    ax.set_ylabel('True Label', fontsize=12, fontweight='bold')
    ax.set_title('Confusion Matrix - Proof of Real Image Classification',
                 fontsize=14, fontweight='bold')

    plt.tight_layout()
    plt.savefig(output_file, dpi=150, bbox_inches='tight')
    print(f"âœ… Confusion matrix saved to: {output_file}")
    plt.close()

    return cm, all_labels, all_preds


def print_classification_report(all_labels, all_preds):
    """
    ã‚¯ãƒ©ã‚¹ã”ã¨ã®è©³ç´°ãªåˆ†é¡æ€§èƒ½ã‚’è¡¨ç¤º

    ã€è¡¨ç¤ºå†…å®¹ã€‘
    - Precisionï¼ˆé©åˆç‡ï¼‰: äºˆæ¸¬ã—ãŸä¸­ã§å®Ÿéš›ã«æ­£ã—ã‹ã£ãŸå‰²åˆ
    - Recallï¼ˆå†ç¾ç‡ï¼‰: å®Ÿéš›ã®ã‚¯ãƒ©ã‚¹ã®ä¸­ã§æ­£ã—ãäºˆæ¸¬ã§ããŸå‰²åˆ
    - F1-score: Precisionã¨Recallã®èª¿å’Œå¹³å‡
    - Support: å„ã‚¯ãƒ©ã‚¹ã®ã‚µãƒ³ãƒ—ãƒ«æ•°

    Args:
        all_labels: çœŸã®ãƒ©ãƒ™ãƒ«
        all_preds: äºˆæ¸¬ãƒ©ãƒ™ãƒ«
    """
    # CIFAR-10ã®ã‚¯ãƒ©ã‚¹å
    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',
                   'dog', 'frog', 'horse', 'ship', 'truck']

    print("\n" + "="*80)
    print("ğŸ“Š DETAILED CLASSIFICATION REPORT (Proof of Real Classification)")
    print("="*80)

    # åˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
    report = classification_report(all_labels, all_preds,
                                   target_names=class_names,
                                   digits=4)
    print(report)

    # ã‚¯ãƒ©ã‚¹ã”ã¨ã®ç²¾åº¦ã‚’è¨ˆç®—
    print("\n" + "="*80)
    print("ğŸ¯ Per-Class Accuracy")
    print("="*80)

    cm = confusion_matrix(all_labels, all_preds)
    for i, class_name in enumerate(class_names):
        class_acc = cm[i, i] / cm[i, :].sum() * 100 if cm[i, :].sum() > 0 else 0
        print(f"{class_name:12s}: {class_acc:6.2f}% ({cm[i, i]:4d}/{cm[i, :].sum():4d})")

    print("="*80)


def print_comparison_summary(results, num_rounds):
    """
    æ¯”è¼ƒçµæœã®ã‚µãƒãƒªãƒ¼ã‚’æ¨™æº–å‡ºåŠ›
    """
    print("\n" + "="*80)
    print("ğŸ“ˆ COMPARISON SUMMARY")
    print("="*80)

    print(f"\nğŸ”‘ CKKS Key Generation Time: {results['ckks']['key_gen_time']:.2f} seconds")
    print("   (This time is not included in round execution times)")

    print("\n" + "-"*80)
    print("ğŸ“Š Accuracy Comparison (per round):")
    print("-"*80)
    print(f"{'Round':<15} {'Plain (%)':<15} {'CKKS (%)':<15} {'Difference':<15}")
    print("-"*80)

    for i in range(num_rounds + 1):
        round_name = "Initial" if i == 0 else f"Round {i}"
        plain_acc = results['plain']['accuracy'][i]
        ckks_acc = results['ckks']['accuracy'][i]
        diff = ckks_acc - plain_acc
        print(f"{round_name:<15} {plain_acc:>8.2f}%      {ckks_acc:>8.2f}%      {diff:>+8.2f}%")

    print("\n" + "-"*80)
    print("â±ï¸  Execution Time Comparison (per round):")
    print("-"*80)
    print(f"{'Round':<15} {'Plain (s)':<15} {'CKKS (s)':<15} {'Overhead':<15}")
    print("-"*80)

    for i in range(num_rounds):
        plain_time = results['plain']['time'][i]
        ckks_time = results['ckks']['time'][i]
        overhead = ((ckks_time / plain_time) - 1) * 100
        print(f"Round {i+1:<8} {plain_time:>8.2f}s      {ckks_time:>8.2f}s      {overhead:>+8.1f}%")

    # å¹³å‡å€¤
    avg_plain_time = np.mean(results['plain']['time'])
    avg_ckks_time = np.mean(results['ckks']['time'])
    avg_overhead = ((avg_ckks_time / avg_plain_time) - 1) * 100

    print("-"*80)
    print(f"{'Average':<15} {avg_plain_time:>8.2f}s      {avg_ckks_time:>8.2f}s      {avg_overhead:>+8.1f}%")
    print("-"*80)

    print("\n" + "="*80)


# =========================================================
# å®Ÿè¡Œã‚¨ãƒ³ãƒˆãƒªãƒã‚¤ãƒ³ãƒˆ
# =========================================================
def main():
    """
    æ¯”è¼ƒå®Ÿé¨“ã®ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    parser = argparse.ArgumentParser(
        description='Federated Learning Comparison: Plain vs CKKS Encrypted with CIFAR-10'
    )
    parser.add_argument('--clients', type=int, default=10, help='Number of clients (default: 10)')
    parser.add_argument('--rounds', type=int, default=10, help='Number of federated learning rounds (default: 10)')
    parser.add_argument('--batch-size', type=int, default=64, help='Batch size (default: 64)')
    parser.add_argument('--local-epochs', type=int, default=1, help='Local epochs per round (default: 1)')
    parser.add_argument('--lr', type=float, default=0.01, help='Learning rate (default: 0.01)')
    parser.add_argument('--iid', action='store_true', help='Use IID data partitioning (default: non-IID)')
    parser.add_argument('--alpha', type=float, default=0.5, help='Dirichlet alpha for non-IID (default: 0.5)')
    parser.add_argument('--seed', type=int, default=42, help='Random seed (default: 42)')
    parser.add_argument('--data-dir', type=str, default='./data', help='Data directory (default: ./data)')
    parser.add_argument('--bn-mode', choices=['fedavg', 'fedbn'], default='fedavg',
                        help='fedbn ã§ BN ã® running_mean/var ã‚’é›†ç´„ã‹ã‚‰é™¤å¤–ï¼ˆå„ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã«ä¿æŒï¼‰')

    args = parser.parse_args()

    print(f"Starting federated learning with {args.clients} clients and {args.rounds} rounds")
    print(f"Batch size: {args.batch_size}, Local epochs: {args.local_epochs}, LR: {args.lr}")
    print(f"Data partitioning: {'IID' if args.iid else f'non-IID (alpha={args.alpha})'}")

    # æ¯”è¼ƒå®Ÿé¨“ã‚’å®Ÿè¡Œ
    results, servers = run_federated_learning_comparison(
        num_clients=args.clients,
        num_rounds=args.rounds,
        batch_size=args.batch_size,
        local_epochs=args.local_epochs,
        lr=args.lr,
        iid=args.iid,
        alpha=args.alpha,
        seed=args.seed,
        data_dir=args.data_dir,
        bn_mode=args.bn_mode
    )

    # çµæœã®ã‚µãƒãƒªãƒ¼ã‚’å‡ºåŠ›
    print_comparison_summary(results, args.rounds)

    # ã‚°ãƒ©ãƒ•ã‚’ä½œæˆ
    plot_comparison_results(results, args.rounds, args.clients)

    # =========================================================
    # ğŸ¨ è¦–è¦šçš„è¨¼æ˜: ç”»åƒåˆ†é¡ãŒå®Ÿéš›ã«å‹•ä½œã—ã¦ã„ã‚‹ã“ã¨ã‚’è¨¼æ˜
    # =========================================================
    print("\n" + "="*80)
    print("ğŸ¨ VISUAL PROOF: Demonstrating Real Image Classification")
    print("="*80)

    # ãƒ‡ãƒã‚¤ã‚¹è¨­å®š
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®æº–å‚™
    _, test_transform = build_transforms()
    test_dataset = datasets.CIFAR10(args.data_dir, train=False, download=True, transform=test_transform)
    test_loader = DataLoader(
        test_dataset,
        batch_size=args.batch_size,
        shuffle=False,
        num_workers=2,
        pin_memory=torch.cuda.is_available(),
    )

    # =========================================================
    # å¹³æ–‡ã®é€£åˆå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§è¦–è¦šçš„è¨¼æ˜
    # =========================================================
    plain_server_final = servers['plain']

    print("\n" + "-"*80)
    print("ğŸ“Š PLAIN FEDERATED LEARNING - Visual Proof")
    print("-"*80)
    print(f"ğŸ“ Using the Plain trained model for visual proof.")
    print(f"   This model achieved {results['plain']['accuracy'][-1]:.2f}% accuracy on CIFAR-10.")

    # 1. ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–
    print("\nğŸ¨ Visualizing sample predictions (Plain)...")
    visualize_sample_predictions(
        plain_server_final.global_model,
        test_dataset,
        device,
        num_samples=16,
        output_file=f'sample_predictions_plain_clients{args.clients}.png'
    )

    # 2. æ··åŒè¡Œåˆ—ã‚’ç”Ÿæˆ
    print("\nğŸ“Š Generating confusion matrix (Plain)...")
    cm_plain, all_labels_plain, all_preds_plain = visualize_confusion_matrix(
        plain_server_final.global_model,
        test_loader,
        device,
        output_file=f'confusion_matrix_plain_clients{args.clients}.png'
    )

    # 3. è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
    print("\nğŸ“Š Classification Report (Plain):")
    print_classification_report(all_labels_plain, all_preds_plain)

    # =========================================================
    # CKKSæš—å·åŒ–ã®é€£åˆå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§è¦–è¦šçš„è¨¼æ˜
    # =========================================================
    ckks_server_final = servers['ckks']

    print("\n" + "-"*80)
    print("ğŸ”’ CKKS ENCRYPTED FEDERATED LEARNING - Visual Proof")
    print("-"*80)
    print(f"ğŸ“ Using the CKKS-encrypted trained model for visual proof.")
    print(f"   This model achieved {results['ckks']['accuracy'][-1]:.2f}% accuracy on CIFAR-10.")

    # 1. ã‚µãƒ³ãƒ—ãƒ«ç”»åƒã®äºˆæ¸¬çµæœã‚’å¯è¦–åŒ–
    print("\nğŸ¨ Visualizing sample predictions (CKKS)...")
    visualize_sample_predictions(
        ckks_server_final.global_model,
        test_dataset,
        device,
        num_samples=16,
        output_file=f'sample_predictions_ckks_clients{args.clients}.png'
    )

    # 2. æ··åŒè¡Œåˆ—ã‚’ç”Ÿæˆ
    print("\nğŸ“Š Generating confusion matrix (CKKS)...")
    cm_ckks, all_labels_ckks, all_preds_ckks = visualize_confusion_matrix(
        ckks_server_final.global_model,
        test_loader,
        device,
        output_file=f'confusion_matrix_ckks_clients{args.clients}.png'
    )

    # 3. è©³ç´°ãªåˆ†é¡ãƒ¬ãƒãƒ¼ãƒˆã‚’è¡¨ç¤º
    print("\nğŸ“Š Classification Report (CKKS):")
    print_classification_report(all_labels_ckks, all_preds_ckks)

    print("\n" + "="*80)
    print("âœ… Visual proof completed for both Plain and CKKS!")
    print("="*80)
    print("\nğŸ“„ Generated files:")
    print(f"  1. federated_learning_comparison_clients{args.clients}_rounds{args.rounds}.png")
    print(f"  2. sample_predictions_plain_clients{args.clients}.png")
    print(f"  3. confusion_matrix_plain_clients{args.clients}.png")
    print(f"  4. sample_predictions_ckks_clients{args.clients}.png")
    print(f"  5. confusion_matrix_ckks_clients{args.clients}.png")
    print("\nThese visualizations prove that real image classification is being performed,")
    print("and allow comparison between Plain and CKKS encrypted federated learning!")

    print("\nâœ… All comparisons completed!")


if __name__ == "__main__":
    main()

